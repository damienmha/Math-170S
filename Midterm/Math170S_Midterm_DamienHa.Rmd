---
title: "Math 170S Midterm"
author: "Damien Ha"
date: "2023-02-19"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
---

# Problem 1

```{r}
Class <- c('0-9', '10-19', '20-29', '30-39', '40-49', '50-59')
Frequency <- c(13, 15, 9, 14, 16, 8)
MidPoint <- c(4.5, 14.5, 24.5, 34.5, 44.5, 54.5)
xf <- Frequency * MidPoint
cf <- c(13, 28, 37, 51, 67, 75)
df <- data.frame(Class, Frequency, MidPoint, xf, cf)
df
mean1 <- sum(xf)/75
print(paste0("the mean is ", mean1))
median1 <- 30 + (1/14)*9
print(paste0("the median is ", median1))
variance1 <- (sum(Frequency * ((MidPoint - mean1)^2))) / 75
sd1 <- sqrt(variance1)
print(paste0("the standard deviation is ", sd1))
percentile10 <- ((10*75)/100)/13*9
print(paste0("the 10th percentile is ", percentile10))
q1 <- 14.5 + (6.5/15)*9
q3 <- 44.5 +(6.5/16)*9
iqr1 <- q3 - q1
print(paste0("the first quartile is ", q1))
print(paste0("the IQR is ", iqr1))
```


# Problem 2

## Part A 
```{r}
data("USArrests")
summary(USArrests$Murder)
summary(USArrests$Assault)
summary(USArrests$UrbanPop)
summary(USArrests$Rape)
```

## Part B
```{r}
plot(USArrests$Assault, USArrests$Murder, 
     xlab = "Assault", ylab = "Murder", main = "Assault vs Murder", 
     col = "red", pch = 19)
```

There's a slightly positive trend in the scatterplot. On average, an increase in assaults implies an increase in murders

## Part C
```{r}
summary(lm(USArrests$Murder ~ USArrests$UrbanPop))
```

The intercept is 6.416 suggesting that when we have population 0, we can expect 6.416 murders. We also see the slope is 0.0209 meaning with a 1 unit increase in population, we expect the average murder increase to be 0.0209. The R squared value, however, is relatively low meaning that the model explains very little of the variability in murder, and the p-value of 0.6312 is rather high, suggesting our results are not very statistically significant



\definecolor{hightlightColor}{HTML}{40E0D0}
# Problem 3

## Part A

MLE for $Poisson(\lambda)$

$\text{Poisson distribution: } P(X=x) = \frac{\lambda^xe^{-x}}{x!}$  

$L(\lambda) = \Pi_{i=1}^n \frac{\lambda^xe^{-x}}{x!}$  

$ln(L(\lambda)) = ln(\Pi_{i=1}^n \frac{\lambda^xe^{-x}}{x!})$  

$=\Sigma_{i=1}^n ln(\frac{\lambda^xe^{-x}}{x!})$  

$=\Sigma_{i=1}^n(ln(\lambda^{x_i}) + ln(e^{-\lambda}) - ln(x_i!))$  

$=\Sigma_{i=1}^n(ln(\lambda^{x_i}) - \lambda ln(e) - ln(x_i!))$  

$=\Sigma_{i=1}^n(ln(\lambda^{x_i}) - \lambda - ln(x_i!))$  

$= ln(\lambda) \Sigma_{i=1}^n x_i - n\lambda - \Sigma_{i=1}^n(x_i!)$  

$\frac{d}{d\lambda}ln(L(\lambda)) = \frac{1}{\lambda}\Sigma_{i=1}^nx_i - n$  

$0 = \frac{1}{\lambda}\Sigma_{i=1}^nx_i - n$  

$n = \frac{1}{\lambda}\Sigma_{i=1}^nx_i$  

$n\lambda = \Sigma_{i=1}^nx_i$  

\colorbox{hightlightColor}{${\lambda = \frac{1}{n}\Sigma_{i=1}^nx_i}$}  

## Part B

MLE for $Normal(\mu, \sigma^2)$

$\text{Normal distribution: } f(x \mid \mu , \sigma^2) = \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2}(\frac{x - \mu}{\sigma})^2}$

$L(\mu, \sigma^2) = \Pi_{i=1}^n \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2}(\frac{x - \mu}{\sigma})^2}$

$= \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2\sigma^2} \Sigma_{i=1}^n(x_i-\mu)^2}$

$ln(L(\mu, \sigma^2)) = ln(\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2\sigma^2} \Sigma_{i=1}^n(x_i-\mu)^2})$

$= ln(\frac{1}{\sigma \sqrt{2 \pi}}) + ln(e^{-\frac{1}{2\sigma^2} \Sigma_{i=1}^n(x_i-\mu)^2})$

$= ln((2\pi\sigma^2)^-\frac{n}{2}) + ln(e^{-\frac{1}{2\sigma^2} \Sigma_{i=1}^n(x_i-\mu)^2})$  

$= -\frac{n}{2}ln(2\pi\sigma^2) - \frac{1}{2\sigma^2}\Sigma_{i=1}^n(x_i - \mu)^2$

$= -\frac{n}{2}ln(2\pi) -\frac{n}{2}ln(\sigma^2) - \frac{1}{2\sigma^2}\Sigma_{i=1}^n(x_i - \mu)^2$  
$\frac{\partial}{\partial \mu}ln(L(\mu, \sigma^2)) = \frac{\partial}{\partial \mu}(-\frac{n}{2}ln(2\pi) -\frac{n}{2}ln(\sigma^2) - \frac{1}{2\sigma^2}\Sigma_{i=1}^n(x_i - \mu)^2)$  

$= \frac{1}{\sigma^2} \Sigma_{i=1}^n(x_i - \mu)$  

$= \frac{1}{\sigma^2} (\Sigma_{i=1}^nx_i - n\mu)$  

$0 = \frac{1}{\sigma^2} (\Sigma_{i=1}^nx_i - n\mu)$  

$0 = \Sigma_{i=1}^nx_i - n\mu$  

$n\mu = \Sigma_{i=1}^nx_i$  

\colorbox{hightlightColor}{$\mu = \frac{1}{n}\Sigma_{i=1}^n x_i$}  

$\frac{\partial}{\partial \sigma^2}ln(L(\mu, \sigma^2)) = \frac{\partial}{\partial \sigma^2}(-\frac{n}{2}ln(2\pi) -\frac{n}{2}ln(\sigma^2) - \frac{1}{2\sigma^2}\Sigma_{i=1}^n(x_i - \mu)^2)$  

$= -\frac{n}{2\sigma^2} - (\frac{1}{2} \Sigma_{i=1}^n (x_i - \mu)^2)\frac{d}{d\sigma^2}(\frac{1}{\sigma^2})$  

$= -\frac{n}{2\sigma^2} - (\frac{1}{2} \Sigma_{i=1}^n (x_i - \mu)^2)(-\frac{1}{(\sigma^2)^2})$  

$= -\frac{n}{2\sigma^2} + (\frac{1}{2} \Sigma_{i=1}^n (x_i - \mu)^2)\frac{1}{(\sigma^2)^2}$

$= \frac{1}{2\sigma^2}(\frac{1}{\sigma^2}\Sigma_{i=1}^n(x_i - \mu)^2 - n)$

Let's suppose $\sigma^2 \neq 0$. Then we have

$0 = \frac{1}{2\sigma^2}(\frac{1}{\sigma^2}\Sigma_{i=1}^n(x_i - \mu)^2 - n)$  

$0 = \frac{1}{\sigma^2}\Sigma_{i=1}^n(x_i - \mu)^2 - n$  

$n = \frac{1}{\sigma^2}\Sigma_{i=1}^n(x_i - \mu)^2$

$\sigma^2n = \Sigma_{i=1}^n(x_i - \mu)^2$

\colorbox{hightlightColor}{$\sigma^2 = \frac{1}{n}\Sigma_{i=1}^n(x_i - \mu)^2$}

## Part C

MLE for $Gamma(\alpha)$  

$\text{Gamma distribution: } f(x \mid \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}$  

$L(\alpha, \beta) = \Pi_{i=1}^n \frac{\beta^\alpha}{\Gamma(\alpha)}x_i^{\alpha-1}e^{-\beta x_i}$  

$ln(L(\alpha, \beta)) = \Pi_{i=1}^n(\alpha ln(\beta) - ln(\Gamma(\alpha)) + (\alpha - 1)ln(x_i) - \beta x_i)$  

$\frac{\partial}{\partial \alpha}(ln(L(\alpha, \beta))) = n\alpha ln(\beta) - n ln(\Gamma(\alpha)) + (\alpha - 1)\Sigma_{i=1}^n ln(x_i) - \beta \Sigma_{i=1}^nx_i$  

$0 = n\alpha ln(\beta) - n ln(\Gamma(\alpha)) + (\alpha - 1)\Sigma_{i=1}^n ln(x_i) - \beta \Sigma_{i=1}^nx_i$  

$0 =n ln(\beta) - n\frac{1}{\Gamma(\alpha)}\Gamma'(\alpha) + \Sigma_{i=1}^nln(x_i)$

Let $\Psi(\alpha) = \frac{\Gamma'(\alpha)}{\Gamma(\alpha)}$. We have  

\colorbox{hightlightColor}{$\Psi(\alpha) = ln(\beta) + \frac{1}{n}\Sigma_{i=1}^nln(x_i)$}

## Part D

MLE for $Binomial(p)$

$\text{Binomial distribution: } P(X=x) = {n \choose x}p^x(1-p)^{n-x} = \frac{n!}{(n-x)!x!}p^x(1-p)^{n-x}$  

$L(p) = \Pi_{i=1}^n \frac{n!}{(n-x_i)!x_i!}p^{x_i}(1-p)^{n-x_i}$  

$= (\Pi_{i=1}^n \frac{n!}{(n-x_i)!x_i!}) \Pi_{i=1}^np^{x_i}(1-p)^{n-x_i}$  

$= (\Pi_{i=1}^n \frac{n!}{(n-x_i)!x_i!})p^{x_i}(1-p)^{n-\Sigma_{i=1}^nx_i}$  

$ln(L(P)) = \Sigma_{i=1}^n x_i ln(p) + (n - \Sigma_{i=1}^n x_i)ln(1-p)$  

$\frac{d}{dp}ln(L(p)) = \frac{1}{p}\Sigma_{i=1}^n x_i - (n - \Sigma_{i=1}^n x_i)\frac{1}{1-p}$  

$0 = \frac{1}{p}\Sigma_{i=1}^n x_i - (n - \Sigma_{i=1}^n x_i)\frac{1}{1-p}$  

$0 = \frac{(1-p)\Sigma_{i=1}^n x_i - (n - \Sigma_{i=1}^n x_i)p}{p(1-p)}$  

$0 = (1-p)\Sigma_{i=1}^n x_i - (n - \Sigma_{i=1}^n x_i)p$

$0 = \Sigma_{i=1}^n x_i - p\Sigma_{i=1}^n x_i - np + (\Sigma_{i=1}^n x_i)p$  

$0 = \Sigma_{i=1}^n x_i - np$  

$np = \Sigma_{i=1}^n x_i$  

\colorbox{hightlightColor}{$p = \frac{\Sigma_{i=1}^nx_i}{n}$}

## Part E

MLE for $Geometric(p)$

$\text{Geometric distribution: } f(x \mid p) = (1-p)^{x-1}p$  

$L(p) = \Pi_{i=1}^n(1-p)^{x-1}p$  

$= p^n(1-p)^{\Sigma_{i=1}^nx_i-n}$  

$ln(L(p)) = ln(p^n(1-p)^{\Sigma_{i=1}^nx_i-n})$  

$= n ln(p) + (\Sigma_{i=1}^nx_i-n)ln(1-p)$  

$\frac{d}{dp}ln(L(p)) = \frac{d}{dp}(n ln(p) + (\Sigma_{i=1}^nx_i-n)ln(1-p))$  

$= \frac{n}{p} - \frac{\Sigma_{i=1}^n(x_i-n)}{1-p}$  

$0 = \frac{n}{p} - \frac{\Sigma_{i=1}^n(x_i-n)}{1-p}$

$\frac{n}{p} = \frac{\Sigma_{i=1}^n(x_i-n)}{1-p}$  

$(1-p)\frac{n}{p} = \Sigma_{i=1}^n(x_i-n)$  

$\frac{n}{p} - n = \Sigma_{i=1}^n(x_i-n)$  

$\frac{n}{p} = \Sigma_{i=1}^nx_i$  

$n = p \Sigma_{i=1}^nx_i$

\colorbox{hightlightColor}{$p = \frac{n}{\Sigma_{i=1}^nx_i}$}

## Part F

MLE for $Exponential(\mu)$  

$\text{Exponential distribution: } f(x \mid \mu) = \frac{1}{\mu}e^{\frac{-x}{\mu}}$  

$L(\mu) = \Pi_{i=1}^n \frac{1}{\mu}e^{\frac{-x}{\mu}}$   

$= \frac{1}{\mu^n} e^{\frac{\Sigma_{i=1}^nx_i}{\mu}}$  

$ln(L(\mu)) = -n ln(\mu) - \frac{1}{\mu}\Sigma_{i=1}^n x_i$  

$\frac{d}{d\mu}ln(L(\mu)) = \frac{-n}{\mu} + \frac{1}{\mu^2}\Sigma_{i=1}^nx_i$  

$0 = \frac{-n}{\mu} + \frac{1}{\mu^2}\Sigma_{i=1}^nx_i$  

$\frac{n}{\mu} = \frac{1}{\mu^2}\Sigma_{i=1}^nx_i$   

$\mu n = \Sigma_{i=1}^nx_i$  

\colorbox{hightlightColor}{$\mu = \frac{1}{n}\Sigma_{i=1}^nx_i$}



# Problem 4

## Part A
```{r}
df2 <- data.frame(Y = c(15.4, 18, 19, 22, 27, 30, 38.5, 46, 55, 58, 60, 62, 64.6, 68, 71), 
                 X = c(9.89, 11, 15.3, 15, 17, 19, 20.9, 22, 28, 30.3, 31, 35, 36.6, 38, 39))
summary(lm(df2$Y ~ df2$X))
```

## Part B
```{r}
# R-squared
summary(lm(df2$Y ~ df2$X))[[9]]
# intepretation
print(paste0("the model explains ", summary(lm(df2$Y ~ df2$X))[[9]]*100,  
             "% of variability in Y"))
```

## Part C
```{r}
# Y value when X = 16
summary(lm(df2$Y ~ df2$X))[[4]][[1]] + summary(lm(df2$Y ~ df2$X))[[4]][[2]]*16

# Y value when X = 25
summary(lm(df2$Y ~ df2$X))[[4]][[1]] + summary(lm(df2$Y ~ df2$X))[[4]][[2]]*25
```



# Problem 5
## Part A
```{r}
library("MASS")
data("Boston")
l <- list(crim = Boston$crim, rad = Boston$rad)
meanMedianSDiqr <- function(x){
  c(mean = mean(x), median = median(x), standard_deviation = sd(x), iqr = IQR(x))
}
print(sapply(l, meanMedianSDiqr))
```

## Part B
```{r}
boxplot(Boston$nox[which(Boston$chas == 1)], Boston$nox[which(Boston$chas == 0)],
        main = "Boxplot of Nitrogen Oxide Concentrates", 
        col = c("darkgreen", "gold"), names = c("track bounds river", "other"))
```

## Part C
```{r}
plot(Boston$medv, Boston$age, xlab = "medv", ylab = "age", main = "medv vs age", 
     col = 4, pch = 19)
```

There doesn't seem to be any particular trend in the scatterplot. Rather, the points seem to be scattered randomly, so medv and age may not be strongly linearly correlated. Some notable features are that there are fewer points in the lower left at the portion of the graph representing low age and low medv so there is no data for young people with medv, and that there are more points clustered together in the middle of the plot compared to the far right perhaps suggesting that higher levels of medv aren't too common.

## Part D
```{r}
# crim 95% confidence interval
c(mean(Boston$crim) - (pt(unname(t.test(Boston$crim)[[1]]),  
                          length(Boston$crim-1)))*(sd(Boston$crim)/length(Boston$crim)), 
  mean(Boston$crim) + (pt(unname(t.test(Boston$crim)[[1]]),  
                          length(Boston$crim-1)))*(sd(Boston$crim)/length(Boston$crim)))

# tax 95% confidence interval
c(mean(Boston$tax) - (pt(unname(t.test(Boston$tax)[[1]]), 
                         length(Boston$tax-1)))*(sd(Boston$tax)/length(Boston$tax)), 
  mean(Boston$tax) + (pt(unname(t.test(Boston$tax)[[1]]), 
                         length(Boston$tax-1)))*(sd(Boston$tax)/length(Boston$tax)))
```

## Part E
```{r}
summary(lm(Boston$medv ~ Boston$crim))
# R-squared
summary(lm(Boston$medv ~ Boston$crim))[[9]]
# Interpretation
print(paste0("the model explains ", summary(lm(Boston$medv ~ Boston$crim))[[9]]*100, 
             "% of the variability in medv"))
```

The very low p-value suggests our results are statistically significant. The intercept of 24.03311 suggests that at 0 crim, we can expect 24.03311 crim on average. Our slope of -0.41519 suggest that with a 1 unit increase in crim, we see an 0.41519 descrease in medv


# Problem 6
$X \sim Normal(\mu, \sigma_0^2)$  

PDF: $\frac{1}{\sigma_0 \sqrt{2 \pi}} e^{-\frac{1}{2}(\frac{x - \mu}{\sigma_0})^2}$  

$L(\mu, \sigma_0^2) = \Pi_{i=1}^n (\frac{1}{\sigma_0 \sqrt{2 \pi}}) e^{-\frac{1}{2}(\frac{x - \mu}{\sigma_0})^2}$ 

$=(\frac{1}{\sigma_0 \sqrt{2 \pi}})^n e^{-\frac{1}{2}\Sigma_{i=1}^n(\frac{x_i-\mu}{\sigma_0})^2}$

Prior distribution: $M \sim Normal(\mu_0, \rho_0)$  

PDF: $n(\mu) = \frac{1}{\rho_0 \sqrt{2\pi}} e^{-\frac{1}{2}(\frac{\mu - \mu_0}{\rho_0})^2}$  

WTS posterior density is $P_{\gamma_M}(\mu \mid x_1, ..., x_n) = \kappa e^{\frac{-(\mu-c)^2}{2\tau^2}}$  

$P_\mu(\mu \mid x_1, ..., x_n) = (\frac{1}{\sigma_0\sqrt{2\pi}})^n e^{-\frac{1}{2}\Sigma_{i=1}^n(\frac{x_i-\mu}{\sigma_0})^2} \cdot \frac{1}{\rho_0\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{\mu-\mu_0}{\rho_0})^2}$

$=(\frac{1}{\sigma_0\sqrt{2\pi}})^n\frac{1}{\sigma_0\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{\mu-\mu_0}{\rho_0})^2 + \frac{1}{\sigma_0^2}\Sigma_{i=1}^n(x_i-\mu)^2}$  

$= e^{-\frac{1}{2}(\frac{1}{\rho_0}(\mu^2 -2\mu\mu_0 + mu_0^2) + \frac{1}{\sigma^2}(\Sigma_{i=1}^nx_i^2 - 2\mu\Sigma_{i=1}^n + n\mu^2))}$  

$=e^{-\frac{1}{2}\frac{\Sigma_{i=1}^nx_i^2}{\sigma_0^2} + \frac{\mu_0^2}{\rho_0^2}} \cdot e^{-\frac{1}{2}(\frac{1}{\rho^3}(\mu_2-2\mu\mu_0)-\frac{2\mu}{\sigma_0^2}\Sigma_{i=1}^nx_i = \frac{n-\mu^2}{\sigma_0^2})}$  

$=e^{-\frac{1}{2}\frac{\mu^2}{\rho_0^2}-\frac{2\mu\mu_0}{\rho_0^2}-\frac{2\mu}{\sigma_0^2}\Sigma_{i=1}^nx_i + \frac{n\mu^2}{\sigma_0^2}}$  

$= e^{-\frac{1}{2}\frac{\sigma_0^2\mu^2 - \sigma_0^22\mu\mu_0 - 2\rho_0^2\mu\Sigma_{i=1}^nx_i + n\mu^2\rho_0^2}{\sigma_0^2\rho_0^2}}$  

$= e^{-\frac{1}{2}\frac{\mu^2(\sigma_0^2 + n\rho_0^2) - 2\mu(\sigma_0^2\mu_0 = \rho_0^2\Sigma_{i=1}^nx_i)}{\sigma_0^2\rho_0^2}}$  

$= e^{-\frac{1}{2} \frac{\mu^2 - 2\mu\frac{(\sigma_0^2\mu_0 = \rho_0^2\Sigma_{i=1}^nx_i)}{\sigma_0^2 + n\rho_0^2}}{\frac{\sigma_0^2\rho_0^2}{\sigma_0^2+n\rho_0^2}}}$  

$= e^{-\frac{1}{2} \frac{\mu - (\frac{(\sigma_0^2\mu_0 = \rho_0^2\Sigma_{i=1}^nx_i)}{\sigma_0^2 + n\rho_0^2})^2}{\frac{\sigma_0^2\rho_0^2}{\sigma_0^2+n\rho_0^2}}}$  

$P_\mu(\mu \mid x_1, ..., x_n) = \kappa e^{\frac{-(\mu - c)^2}{2\tau^2}}$ where $c= \frac{\sigma_0^2\mu_0 +\rho_0^2\Sigma_{i=1}^nx_i}{\sigma_0^2 + n\rho_0^2}$ and $\tau = \sqrt{\frac{\sigma^2\rho_0^2}{\sigma^2+n\rho_0^2}} = \frac{\sigma\rho_0}{\sqrt{\sigma^2+n\rho_0^2}}$



# Problem 7
```{r}
sigma_w <- sqrt(((5.2^2)/40)+((3.98^2)/49))
# confidence interval
c(14.5-13.75-(qnorm(p=.01/2, lower.tail=F)*sigma_w),  
  14.5-13.75+(qnorm(p=.01/2, lower.tail=F)*sigma_w))

# interpretation/conclusion
print(paste0("we're 99% confident the true difference in means lies between ",  
             c(14.5-13.75-(qnorm(p=.01/2, lower.tail=F)*sigma_w),  
               14.5-13.75+(qnorm(p=.01/2, lower.tail=F)*sigma_w))[[1]],  
             " and ", c(14.5-13.75-(qnorm(p=.01/2, lower.tail=F)*sigma_w), 
                        14.5-13.75+(qnorm(p=.01/2, lower.tail=F)*sigma_w))[[2]]))
```

Since the confidence interval includes 0, there is a good chance that there is not a significant difference between the two means
